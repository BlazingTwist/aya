import ::matrix

.# Sigmoid helper functions
{:1 * Me 1+ 1\/}:sigmoid;
{:& 1\- *}:dsigmoid;

.# Neural Net class
class nn

def nn::__init__ {x y self,
    x self.:input;
    y self.:y;
    yE matrix.zeros self.:output;
    .# Randomly initialize weights
    [xE1I 4] matrixQ self.:weights_a;
    [4    1] matrixQ self.:weights_b;
}


def nn::feedforward {self : sigmoid^,
    self.input   self.weights_a .dot sigmoid self.:layer_a;
    self.layer_a self.weights_b .dot sigmoid self.:output;
}


def nn::backprop {self : dsigmoid^ d d_weights_a d_weights_b,
    self.y self.output - 2 * self.output dsigmoid * :d;

    self.layer_a.t d .dot :d_weights_b;

    self.input.t
    d self.weights_b.t .dot self.layer_a dsigmoid *
    .dot :d_weights_a;

    self.weights_a d_weights_a + self.:weights_a;
    self.weights_b d_weights_b + self.:weights_b;
}


def nn::loss {self,
    self.y self.output - 2^ .mean
}

main {
    import ::plot

    .# Data
    [[0 0 1][0 1 1][1 0 1][1 1 1]] matrix! :x;
    [[0][1][1][0]] matrix!:y;

    x y nn! :net;
    []:loss;

    .# Train for 1000 steps
    {
        net.feedforward
        net.backprop
        net.loss :m loss .B ;
    } 1000 %

    lossER loss plot.line :plt;
    "Neural Net Example" plt.:title;
    "Loss" plt.:ylabel;
    "Iteration" plt.x.:label;
    plt.view
}
